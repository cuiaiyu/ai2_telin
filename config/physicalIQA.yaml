physicaliqa:
  roberta:
    roberta-large:
      lr: 5e-6
      batch_size: 8
    large_roberta:
      lr: 5e-6
      batch_size: 4
    lm_with_dp_graphs_gtn1L_fcn_dpbatch1_multitask_beta_0p001_10000:
      lr: 5e-6
      batch_size: 4
      dropout: 0.1
      accumulate_grad_batches: 2
      max_nb_epochs: 4
    lm_with_dp_graphs_gtn1L_fcn_dpbatch1_multitask_beta_0p001_12000:
      lr: 5e-6
      batch_size: 4
      dropout: 0.1
      accumulate_grad_batches: 2
      max_nb_epochs: 4
    mutimodal_lm_large_finetune_cc_cn_dc_30000:
      lr: 5e-6
      batch_size: 4
      dropout: 0.1
      accumulate_grad_batches: 4
    baseline2:
      lr: 5e-6
      batch_size: 8
      dropout: 0.1
      max_nb_epochs: 3
    baseline3:
      lr: 5e-6
      batch_size: 8
      dropout: 0
      max_nb_epochs: 3
    baseline4:
      lr: 5e-6
      batch_size: 16
      dropout: 0.5
      max_nb_epochs: 3
    baseline5:
      lr: 5e-6
      batch_size: 16
      dropout: 0.5
      max_nb_epochs: 3
    baseline6:
      lr: 5e-6
      batch_size: 16
      dropout: 0
      max_nb_epochs: 3
    baseline7:
      lr: 5e-6
      batch_size: 16
      dropout: 0
      max_nb_epochs: 3
    baseline8:
      lr: 5e-6
      batch_size: 16
      dropout: 0.1
      max_nb_epochs: 3
    baseline9:
      lr: 5e-6
      batch_size: 16
      dropout: 0.1
      max_nb_epochs: 3
  default:
    seed: 42
    lr: 2e-5
    dropout: 0.5
    batch_size: 32
    max_seq_len: 128
    max_nb_epochs: 3
    initializer_range: 0.02
    weight_decay: 0.0
    warmup_steps: 0
    adam_epsilon: 1e-8
    accumulate_grad_batches: 1
    do_lower_case: false
