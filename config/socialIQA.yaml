socialiqa:
  roberta:
    large_roberta_attr_qa_grad_accu_2: 
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 2
    large-atomic-50k:  
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-atomic-100k:  
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-atomic-no-personx-150k:  
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-atomic-no-personx-200k:  
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-atomic-no-personx-250k:  
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-atomic-no-personx-100000:  
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-atomic-no-personx-50000:  
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-atomic-not-natural-100000:
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-atomic-not-natural-50000:  
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-concept-net-densecap-video-checkpoint-60000-copied:
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large-concept-net-densecap-video-checkpoint-20000-copied:
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    2hop_CN_10000:
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 4
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    multi_large_finetuned_v3_26000:
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 4
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    multi_large_finetuned_v2_24000:
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 4
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    multi_large_finetuned_v1_12000:
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 4
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
    large_roberta:
      seed: 42
      lr: 5e-6
      dropout: 0.1
      batch_size: 3
      max_seq_len: 128
      max_nb_epochs: 3
      initializer_range: 0.02
      weight_decay: 0.0
      warmup_steps: 0
      adam_epsilon: 1e-8
      accumulate_grad_batches: 1
      do_lower_case: false
  default:
    seed: 42
    lr: 5e-6
    dropout: 0.1
    batch_size: 3
    max_seq_len: 128
    max_nb_epochs: 3
    initializer_range: 0.02
    weight_decay: 0.0
    warmup_steps: 0
    adam_epsilon: 1e-8
    accumulate_grad_batches: 1
    do_lower_case: false
